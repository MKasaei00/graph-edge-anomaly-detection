{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9kjFPcOU3Tm"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHqQB7qqASp_"
      },
      "source": [
        "## Preparing data files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone"
      ],
      "metadata": {
        "id": "FVBgGmk1yzQ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJp88anQJbSg",
        "outputId": "38be8e6b-8547-4fd9-c3da-3dd672553cd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'graph-edge-anomaly-detection'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 99 (delta 12), reused 75 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (99/99), 217.64 MiB | 16.32 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Updating files: 100% (80/80), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!rm -rf /content/graph-edge-anomaly-detection\n",
        "!git clone https://github.com/MKasaei00/graph-edge-anomaly-detection.git --depth 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### unzip full result csv files"
      ],
      "metadata": {
        "id": "kCtBkq7ly03_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IG_vs9sJ1nk"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install unrar  # Install unrar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76_egtLTKR6M"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujoOTqtG-cKC"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/merged_data\n",
        "!mkdir /content/merged_data/\n",
        "!mkdir /content/merged_data/DARPA\n",
        "!mkdir /content/merged_data/ISCX\n",
        "!mkdir /content/merged_data/IDS2018\n",
        "!mkdir /content/merged_data/DDOS2019"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR3EhU3J7hWj"
      },
      "outputs": [],
      "source": [
        "!unrar x /content/graph-edge-anomaly-detection/datasets/DARPA/meta.rar /content/merged_data/DARPA\n",
        "!unrar x /content/graph-edge-anomaly-detection/datasets/ISCX/meta.rar /content/merged_data/ISCX\n",
        "!unzip /content/graph-edge-anomaly-detection/datasets/IDS2018/merged_data.zip -d /content/merged_data/IDS2018/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_SpZda1kD6gZ",
        "outputId": "c9a3636b-1145-4b0e-eec1-4f97a9b78bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/graph-edge-anomaly-detection/datasets/DDOS2019/merged_data.rar\n",
            "\n",
            "Extracting  /content/merged_data/DDOS2019/merged_data.csv                \b\b\b\b  7%\b\b\b\b 15%\b\b\b\b 23%\b\b\b\b 31%\b\b\b\b 39%\b\b\b\b 47%\b\b\b\b 55%\b\b\b\b 63%\b\b\b\b 71%\b\b\b\b 79%\b\b\b\b 87%\b\b\b\b 95%\b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ],
      "source": [
        "!unrar x /content/graph-edge-anomaly-detection/datasets/DDOS2019/merged_data.rar /content/merged_data/DDOS2019/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Algorithms"
      ],
      "metadata": {
        "id": "_YPOYHFOuN6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize"
      ],
      "metadata": {
        "id": "N5pseiuaug72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Change directory to /content/graph-edge-anomaly-detection/AnoEdge/code/\n",
        "%cd /content/graph-edge-anomaly-detection/AnoEdge/code/"
      ],
      "metadata": {
        "id": "ojVSdSP-mkRQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557310c7-33b8-4a26-a82b-3f44eb756980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/graph-edge-anomaly-detection/AnoEdge/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgXJ28kMkabu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad828f5-55e5-4fa5-9cd8-1402f426331b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "dos2unix is already the newest version (7.4.2-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Usage: dos2unix [options] [file ...] [-n infile outfile ...]\n",
            " --allow-chown         allow file ownership change\n",
            " -ascii                convert only line breaks (default)\n",
            " -iso                  conversion between DOS and ISO-8859-1 character set\n",
            "   -1252               use Windows code page 1252 (Western European)\n",
            "   -437                use DOS code page 437 (US) (default)\n",
            "   -850                use DOS code page 850 (Western European)\n",
            "   -860                use DOS code page 860 (Portuguese)\n",
            "   -863                use DOS code page 863 (French Canadian)\n",
            "   -865                use DOS code page 865 (Nordic)\n",
            " -7                    convert 8 bit characters to 7 bit space\n",
            " -b, --keep-bom        keep Byte Order Mark\n",
            " -c, --convmode        conversion mode\n",
            "   convmode            ascii, 7bit, iso, mac, default to ascii\n",
            " -f, --force           force conversion of binary files\n",
            " -h, --help            display this help text\n",
            " -i, --info[=FLAGS]    display file information\n",
            "   file ...            files to analyze\n",
            " -k, --keepdate        keep output file date\n",
            " -L, --license         display software license\n",
            " -l, --newline         add additional newline\n",
            " -m, --add-bom         add Byte Order Mark (default UTF-8)\n",
            " -n, --newfile         write to new file\n",
            "   infile              original file in new-file mode\n",
            "   outfile             output file in new-file mode\n",
            " --no-allow-chown      don't allow file ownership change (default)\n",
            " -o, --oldfile         write to old file (default)\n",
            "   file ...            files to convert in old-file mode\n",
            " -q, --quiet           quiet mode, suppress all warnings\n",
            " -r, --remove-bom      remove Byte Order Mark (default)\n",
            " -s, --safe            skip binary files (default)\n",
            " -u,  --keep-utf16     keep UTF-16 encoding\n",
            " -ul, --assume-utf16le assume that the input format is UTF-16LE\n",
            " -ub, --assume-utf16be assume that the input format is UTF-16BE\n",
            " -v,  --verbose        verbose operation\n",
            " -F, --follow-symlink  follow symbolic links and convert the targets\n",
            " -R, --replace-symlink replace symbolic links with converted files\n",
            "                         (original target files remain unchanged)\n",
            " -S, --skip-symlink    keep symbolic links and targets unchanged (default)\n",
            " -V, --version         display version number\n",
            "Usage: dos2unix [options] [file ...] [-n infile outfile ...]\n",
            " --allow-chown         allow file ownership change\n",
            " -ascii                convert only line breaks (default)\n",
            " -iso                  conversion between DOS and ISO-8859-1 character set\n",
            "   -1252               use Windows code page 1252 (Western European)\n",
            "   -437                use DOS code page 437 (US) (default)\n",
            "   -850                use DOS code page 850 (Western European)\n",
            "   -860                use DOS code page 860 (Portuguese)\n",
            "   -863                use DOS code page 863 (French Canadian)\n",
            "   -865                use DOS code page 865 (Nordic)\n",
            " -7                    convert 8 bit characters to 7 bit space\n",
            " -b, --keep-bom        keep Byte Order Mark\n",
            " -c, --convmode        conversion mode\n",
            "   convmode            ascii, 7bit, iso, mac, default to ascii\n",
            " -f, --force           force conversion of binary files\n",
            " -h, --help            display this help text\n",
            " -i, --info[=FLAGS]    display file information\n",
            "   file ...            files to analyze\n",
            " -k, --keepdate        keep output file date\n",
            " -L, --license         display software license\n",
            " -l, --newline         add additional newline\n",
            " -m, --add-bom         add Byte Order Mark (default UTF-8)\n",
            " -n, --newfile         write to new file\n",
            "   infile              original file in new-file mode\n",
            "   outfile             output file in new-file mode\n",
            " --no-allow-chown      don't allow file ownership change (default)\n",
            " -o, --oldfile         write to old file (default)\n",
            "   file ...            files to convert in old-file mode\n",
            " -q, --quiet           quiet mode, suppress all warnings\n",
            " -r, --remove-bom      remove Byte Order Mark (default)\n",
            " -s, --safe            skip binary files (default)\n",
            " -u,  --keep-utf16     keep UTF-16 encoding\n",
            " -ul, --assume-utf16le assume that the input format is UTF-16LE\n",
            " -ub, --assume-utf16be assume that the input format is UTF-16BE\n",
            " -v,  --verbose        verbose operation\n",
            " -F, --follow-symlink  follow symbolic links and convert the targets\n",
            " -R, --replace-symlink replace symbolic links with converted files\n",
            "                         (original target files remain unchanged)\n",
            " -S, --skip-symlink    keep symbolic links and targets unchanged (default)\n",
            " -V, --version         display version number\n"
          ]
        }
      ],
      "source": [
        "# prompt: fix line separator  to be  compatible with linux\n",
        "\n",
        "# fix line separator\n",
        "!apt-get install dos2unix -q\n",
        "!find /content/graph-edge-anomaly-detection/AnoEdge/code/demo.sh -type f -print0 | xargs -0 dos2unix --no-newline -k\n",
        "!find /content/graph-edge-anomaly-detection/AnoEdge/code/Makefile -type f -print0 | xargs -0 dos2unix --no-newline -k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnpaBGX0kYiO"
      },
      "source": [
        "## Run algorithm- not parallel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Run .sh file\n",
        "\n",
        "!chmod +x /content/graph-edge-anomaly-detection/AnoEdge/code/demo.sh"
      ],
      "metadata": {
        "id": "OMeGFTQgl7M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: replace ~/envs/local/bin/pip and ~/envs/local/bin/python with simple versions without env\n",
        "# in file demo.sh  mentioned above\n",
        "\n",
        "# Read the content of the file\n",
        "with open('/content/graph-edge-anomaly-detection/AnoEdge/code/demo.sh', 'r') as file:\n",
        "    file_content = file.read()\n",
        "\n",
        "# Replace the strings\n",
        "file_content = file_content.replace('~/envs/local/bin/pip', 'pip')\n",
        "file_content = file_content.replace('~/envs/local/bin/python', 'python')\n",
        "\n",
        "# Write the modified content back to the file\n",
        "with open('/content/graph-edge-anomaly-detection/AnoEdge/code/demo.sh', 'w') as file:\n",
        "    file.write(file_content)\n",
        "\n",
        "print(\"Replacement complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDQrL1bmnGje",
        "outputId": "44fc7fe3-e291-4824-c719-c2e8037d3436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replacement complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/graph-edge-anomaly-detection/AnoEdge/code/demo.sh DARPA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_04moqpms3O",
        "outputId": "e76ff3d4-dc27-4d30-f488-468fe1477286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm -rf main *.o\n",
            "g++ -Wall -g -O3 -std=c++17 -c anoedgeglobal.cpp\n",
            "g++ -Wall -g -O3 -std=c++17 -c hcms.cpp\n",
            "g++ -Wall -g -O3 -std=c++17 -c main.cpp\n",
            "g++ -Wall -g -O3 -std=c++17 -c utils.cpp\n",
            "g++ -o main anoedgeglobal.o hcms.o main.o utils.o\n",
            "Running AnoEdge-G\n",
            "Installing python dependencies\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRunning python metrics\n",
            "anoedge_g,DARPA\n",
            "AUC: 0.971\n",
            "Time: 58.6454s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run algorithm parallel"
      ],
      "metadata": {
        "id": "ayhAmKz6uIbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize function"
      ],
      "metadata": {
        "id": "yjZac_0lxA1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def remove_data_files(directory):\n",
        "  \"\"\"Removes files named Data_00.csv or Data_0n.csv from a directory.\n",
        "\n",
        "  Args:\n",
        "    directory: The path to the directory.\n",
        "  \"\"\"\n",
        "  for filename in os.listdir(directory):\n",
        "    if re.match(r'Data_\\d+', filename) or re.match(r'Label_\\d+', filename):\n",
        "      filepath = os.path.join(directory, filename)\n",
        "      try:\n",
        "        os.remove(filepath)\n",
        "        print(f\"Removed: {filepath}\")\n",
        "      except OSError as e:\n",
        "        print(f\"Error removing file {filepath}: {e}\")\n",
        "  print(f'deletion completed for path {directory}')"
      ],
      "metadata": {
        "id": "PTURqsbkz32b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Define a function that gets a directory and another value that is degree of paralleism\n",
        "# after that you have to parallelize my streaming algorithm in a way that you have  p instances where first edge in the csv is going to be processed in and second to 2 and so on and return round robin\n",
        "# in fact you can % to do the job in python\n",
        "# after that you have to create multiple csv files that seperates the input to p files\n",
        "# please define a function like that\n",
        "# Your fist argument is exactly a file and produce files near that with _01,_02,..  postfix at the end\n",
        "\n",
        "import os\n",
        "\n",
        "def parallelize_csv(dataset_directory, base_file_name, num_parallel, has_header=False):\n",
        "  \"\"\"\n",
        "  Splits a large CSV file into smaller files based on a round-robin distribution\n",
        "  of rows, considering the edge index.\n",
        "\n",
        "  Args:\n",
        "    dataset_directory: The path to the input CSV file.\n",
        "    num_parallel: The number of parallel files to create.\n",
        "  \"\"\"\n",
        "  output_files = []\n",
        "  ext = '.csv'\n",
        "  base_dir = os.path.dirname(dataset_directory)\n",
        "  dataset_name = os.path.basename(dataset_directory)\n",
        "  input_file = f'{base_dir}{os.path.sep}{dataset_name}{os.path.sep}{base_file_name}'\n",
        "\n",
        "  for i in range(num_parallel):\n",
        "    output_directory = f'{base_dir}{os.path.sep}{dataset_name}_{i+1:02d}'\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.mkdir(output_directory)\n",
        "    output_files.append(open(f\"{output_directory}{os.path.sep}{base_file_name}\", 'w'))\n",
        "\n",
        "  with open(input_file, 'r') as infile:\n",
        "    if has_header:\n",
        "      # Read the header\n",
        "      header = infile.readline()\n",
        "      for outfile in output_files:\n",
        "        outfile.write(header)\n",
        "\n",
        "    # Process the rest of the rows\n",
        "    for i, line in enumerate(infile):\n",
        "      output_files[i % num_parallel].write(line)\n",
        "\n",
        "  for outfile in output_files:\n",
        "    outfile.close()\n",
        "\n",
        "  print(f\"Split {input_file} into {num_parallel} files.\")"
      ],
      "metadata": {
        "id": "3l5YZEZsuLJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasets"
      ],
      "metadata": {
        "id": "GIpfz9G5yTZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DARPA"
      ],
      "metadata": {
        "id": "BiJ0iSDOySJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remove_data_files('/content/graph-edge-anomaly-detection/AnoEdge/data/DARPA/')\n",
        "parallelize_csv('/content/graph-edge-anomaly-detection/AnoEdge/data/DARPA','Data.csv', 8)\n",
        "parallelize_csv('/content/graph-edge-anomaly-detection/AnoEdge/data/DARPA','Label.csv', 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfSu88wgyXqn",
        "outputId": "71d532ab-b68c-4838-cb1e-6062de0f755b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deletion completed for path /content/graph-edge-anomaly-detection/AnoEdge/data/DARPA/\n",
            "Split /content/graph-edge-anomaly-detection/AnoEdge/data/DARPA/Data.csv into 8 files.\n",
            "Split /content/graph-edge-anomaly-detection/AnoEdge/data/DARPA/Label.csv into 8 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a code that runs the code in the above block using for not handy\n",
        "# define a function with argument of dataset name and parallelism degree\n",
        "\n",
        "def run_parallel_algo(dataset_name, parallelism_degree):\n",
        "  \"\"\"Runs the parallel algorithm for a given dataset and parallelism degree.\"\"\"\n",
        "  !make clean\n",
        "  !make\n",
        "  for i in range(1, parallelism_degree + 1):\n",
        "    dataset_instance = f'{dataset_name}_{i:02d}'\n",
        "    print(f\"Running for {dataset_instance}\")\n",
        "    !./main anoedge_g {dataset_instance} 2 32 0.9"
      ],
      "metadata": {
        "id": "ehBcJuyl8iDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "run_parallel_algo('DARPA', 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2j6XNEU81Jm",
        "outputId": "157d21fd-4065-4635-86f8-15c12554d826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm -rf main *.o\n",
            "g++ -Wall -g -O3 -std=c++17 -c anoedgeglobal.cpp\n",
            "g++ -Wall -g -O3 -std=c++17 -c hcms.cpp\n",
            "g++ -Wall -g -O3 -std=c++17 -c main.cpp\n",
            "g++ -Wall -g -O3 -std=c++17 -c utils.cpp\n",
            "g++ -o main anoedgeglobal.o hcms.o main.o utils.o\n",
            "Running for DARPA_01\n",
            "Running for DARPA_02\n",
            "Running for DARPA_03\n",
            "Running for DARPA_04\n",
            "Running for DARPA_05\n",
            "Running for DARPA_06\n",
            "Running for DARPA_07\n",
            "Running for DARPA_08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q\n"
      ],
      "metadata": {
        "id": "Jsrtz6k5D8bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python metrics.py --dataset DARPA_01 --time_window 30 --edge_threshold 50\n",
        "!python metrics.py --dataset DARPA_02 --time_window 30 --edge_threshold 50\n",
        "!python metrics.py --dataset DARPA_03 --time_window 30 --edge_threshold 50\n",
        "!python metrics.py --dataset DARPA_04 --time_window 30 --edge_threshold 50\n",
        "!python metrics.py --dataset DARPA_05 --time_window 30 --edge_threshold 50\n",
        "!python metrics.py --dataset DARPA_06 --time_window 30 --edge_threshold 50\n",
        "!python metrics.py --dataset DARPA_07 --time_window 30 --edge_threshold 50\n",
        "!python metrics.py --dataset DARPA_08 --time_window 30 --edge_threshold 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tjN-HDvEF-P",
        "outputId": "88d2f0db-d72c-4474-ceea-e43b9e061550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anoedge_g,DARPA_01\n",
            "AUC: 0.971\n",
            "Time: 7.1572s\n",
            "\n",
            "anoedge_g,DARPA_02\n",
            "AUC: 0.971\n",
            "Time: 8.1600s\n",
            "\n",
            "anoedge_g,DARPA_03\n",
            "AUC: 0.971\n",
            "Time: 8.1678s\n",
            "\n",
            "anoedge_g,DARPA_04\n",
            "AUC: 0.971\n",
            "Time: 7.1954s\n",
            "\n",
            "anoedge_g,DARPA_05\n",
            "AUC: 0.971\n",
            "Time: 8.1962s\n",
            "\n",
            "anoedge_g,DARPA_06\n",
            "AUC: 0.971\n",
            "Time: 8.1554s\n",
            "\n",
            "anoedge_g,DARPA_07\n",
            "AUC: 0.971\n",
            "Time: 7.1672s\n",
            "\n",
            "anoedge_g,DARPA_08\n",
            "AUC: 0.972\n",
            "Time: 8.1562s\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "FVBgGmk1yzQ3",
        "kCtBkq7ly03_",
        "N5pseiuaug72",
        "bnpaBGX0kYiO",
        "yjZac_0lxA1Z"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}